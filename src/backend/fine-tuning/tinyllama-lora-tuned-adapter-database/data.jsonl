{"instruction":"What is the difference between a primary key and a foreign key in a relational schema?","response":"A primary key uniquely identifies each row in a table. A foreign key is an attribute in one table that references the primary key of another table, enforcing referential integrity between the two tables."}
{"instruction":"Explain what a binding mode is in distributed transactions.","response":"Binding mode determines when locks are acquired in a transaction. In “eager” binding, locks are taken at transaction start; in “lazy” binding, locks are acquired only when needed. Eager reduces deadlocks but increases contention."}
{"instruction":"How does snapshot isolation prevent write–write conflicts?","response":"Snapshot isolation provides each transaction with a consistent snapshot at start time; writes go into a private workspace and are only committed if no other concurrent transaction has modified the same data, thus preventing write–write conflicts."}
{"instruction":"Describe how a two-phase locking (2PL) protocol enforces serializability.","response":"In strict 2PL, a transaction acquires locks during the growing phase and holds all locks until it commits, then releases them during the shrinking phase. This prevents conflicting interleavings and ensures serializable schedules."}
{"instruction":"What is the difference between pessimistic and optimistic concurrency control?","response":"Pessimistic control acquires locks on data before use to prevent conflicts, suitable for high-contention scenarios. Optimistic control allows transactions to proceed without locks and checks for conflicts at commit time, suitable for low contention."}
{"instruction":"Explain the concept of “read-your-writes” consistency.","response":"Read-your-writes ensures that once a client writes data, any subsequent reads by that client will reflect that write. It’s a session guarantee preventing a user from reading stale data they themselves just wrote."}
{"instruction":"How does a coordinator detect participant failure in 2PC?","response":"The coordinator uses timeouts: if a participant doesn’t respond to the prepare or commit message within a configured timeout, the coordinator assumes failure and aborts the transaction to avoid blocking indefinitely."}
{"instruction":"What is the role of a log sequence number (LSN) in database recovery?","response":"An LSN uniquely identifies each log record. During recovery, the system uses LSNs to reapply committed transactions’ redo operations and undo uncommitted transactions in the correct order to restore consistency."}
{"instruction":"Describe the difference between physical and logical data fragmentation.","response":"Physical fragmentation splits actual storage structures (e.g., row groups, pages) across devices. Logical fragmentation splits tables at the logical level (rows or columns) without specifying physical storage, letting the system place fragments flexibly."}
{"instruction":"What is a quorum read and why is R+W>N required?","response":"A quorum read reads from at least R replicas; quorum write writes to at least W replicas. R+W>N ensures that any read quorum overlaps with any write quorum, guaranteeing the reader sees the latest write."}
{"instruction":"How does a global transaction ID (GTID) help in distributed replication?","response":"A GTID uniquely identifies each transaction across all nodes. It simplifies failover and replication by allowing replicas to request missing transactions by GTID, ensuring consistency and easier recovery."}
{"instruction":"Explain how a vector clock detects causality in distributed systems.","response":"A vector clock is an array of counters (one per node). On each event, the node increments its counter; clocks are exchanged on communication, and causality (“happened-before”) is inferred by comparing vector values element-wise."}
{"instruction":"What is a deadlock and how can it be detected?","response":"A deadlock occurs when transactions wait in a cycle for each other’s locks. It can be detected by constructing a wait-for graph and looking for cycles; if one is found, the system can abort a transaction to break the deadlock."}
{"instruction":"Describe how log-based recovery uses a write-ahead log (WAL).","response":"In WAL, before modifying data pages, the database writes corresponding log records to the log. On crash recovery, redo operations from the log reapply changes to pages, and undo rolls back uncommitted transactions, ensuring atomicity and durability."}
{"instruction":"What is the difference between synchronous and asynchronous replication?","response":"Synchronous replication waits for writes to be confirmed on replicas before acknowledging the client, ensuring strong consistency but higher latency. Asynchronous replication returns to the client immediately and propagates changes later, reducing latency but risking data loss."}
{"instruction":"Explain the notion of a consensus group in Raft.","response":"In Raft, a consensus group is a set of servers that maintain replicated logs. One leader handles client requests and log replication; followers replicate the leader’s log entries. Consensus is reached when a majority have appended an entry."}
{"instruction":"How does read repair work in eventually consistent systems?","response":"On a read, the system compares versions from multiple replicas; if it finds stale data, it issues background writes (repairs) to outdated replicas, gradually converging all replicas to the latest state."}
{"instruction":"What is a replication lag and how can it be mitigated?","response":"Replication lag is the delay between committing a write on the primary and applying it on replicas. It can be mitigated by batching, optimizing network paths, increasing parallel apply threads, or tuning consistency levels."}
{"instruction":"Describe how sharding keys affect data distribution.","response":"A sharding key’s hash or range determines which shard stores a record. A good sharding key evenly distributes load and data, avoiding hotspots; a poor key can lead to skewed shards and performance bottlenecks."}
{"instruction":"What is the difference between eventual and strong consistency in NoSQL stores?","response":"Eventual consistency only guarantees convergence if no new updates occur, allowing temporary inconsistencies. Strong consistency ensures all reads reflect the latest write, often via quorum or leader-based protocols."}
{"instruction":"Explain the purpose of the coordinator and participant roles in distributed transactions.","response":"The coordinator orchestrates the transaction (prepare/commit/abort), while participants execute and log local operations. The coordinator collects votes and instructs participants to commit or abort, ensuring atomicity across sites."}
{"instruction":"How does vector partitioning differ from range partitioning?","response":"Vector (hash) partitioning assigns data to partitions based on hashing a key’s value, evenly distributing data. Range partitioning assigns based on value ranges (e.g., date intervals), which can lead to data skew but allows range scans."}
{"instruction":"What is Write Skew, and under what isolation level does it occur?","response":"Write skew is a phenomenon where two concurrent transactions read overlapping data and write to disjoint sets, violating general constraints. It can occur under snapshot isolation because transactions see a consistent snapshot and don’t block each other."}
{"instruction":"Describe how a gossip protocol disseminates membership information.","response":"Each node periodically selects random peers to exchange membership lists (including heartbeats). Over rounds, updates propagate probabilistically through the cluster, ensuring eventual knowledge of all live nodes."}
{"instruction":"What is the role of a commit log in HBase?","response":"HBase uses a commit log (WAL) to record all writes before applying them to in-memory MemStores. On crash, the WAL is replayed to recover lost in-memory writes, ensuring durability."}
{"instruction":"Explain the trade-offs between master-slave and multi-master replication.","response":"Master-slave has a single writable master—simpler conflict management but single point of failure. Multi-master allows writes at multiple nodes—better availability and locality but requires conflict detection and resolution."}
{"instruction":"How does chain replication ensure strong consistency?","response":"Chain replication orders replicas in a chain. Writes go from head to tail, and only at the tail is the write considered committed. Reads go from the tail. This linear flow guarantees strong consistency and high throughput."}
{"instruction":"What is the “primary-backup” approach in distributed systems?","response":"Primary-backup uses one node as primary that processes requests and synchronously updates backups. If the primary fails, a backup with the latest state is promoted. It’s simple but can have a failover delay."}
{"instruction":"Describe a hybrid logical clock (HLC).","response":"HLC combines a logical counter with a physical timestamp. On send, if the sender’s clock is ahead, it increments the counter; on receive, it takes the max of physical times and the counter, preserving causality with loosely synchronized clocks."}
{"instruction":"What is the Paxos leader election process?","response":"A node becomes a proposer and issues a Prepare(n) with a unique, higher proposal number. If a majority of acceptors promise not to accept lower numbers, the proposer becomes the leader for that round and can issue Accept requests."}
{"instruction":"Explain session consistency guarantees in distributed stores.","response":"Session consistency ensures monotonic reads (never see older data), read-your-writes (see your own writes), and write-follows-reads (writes occur on the latest state), providing a cohesive experience per client session."}
{"instruction":"How does MVCC (multi-version concurrency control) work?","response":"MVCC stores multiple versions of data items, each tagged with a timestamp or transaction ID. Readers access the version valid at their snapshot time without blocking writers; writers append new versions, enabling high concurrency."}
{"instruction":"What is a checkpoint in database recovery?","response":"A checkpoint writes all dirty pages from buffer to disk and records the current log position. On recovery, the system need only replay logs after the checkpoint, reducing recovery time by truncating earlier log segments."}
{"instruction":"Describe how conflict-free replicated data types (CRDTs) enable convergence.","response":"CRDTs are specially designed data structures with merge functions that are associative, commutative, and idempotent. Concurrent updates on replicas can be merged in any order and still converge to the same state."}
{"instruction":"What is the two generals’ problem and its implication for distributed agreement?","response":"The two generals’ problem shows that in an unreliable network, two parties cannot guarantee coordination due to possible message loss. It implies that absolute certainty in agreement is impossible; practical protocols rely on timeouts and retries."}
{"instruction":"Explain how a directory-based distributed shared memory (DSM) maintains coherence.","response":"A directory tracks which nodes cache each memory block. On writes, the directory invalidates or updates other caches before granting write permission, ensuring coherence across distributed caches."}
{"instruction":"What is a skip list, and how is it used in databases?","response":"A skip list is a probabilistic data structure of layered linked lists that allows O(log n) search, insertion, and deletion. Databases use skip lists (e.g., in Redis) as an in-memory index alternative to B-trees for fast lookups."}
{"instruction":"Describe how Google Bigtable uses SSTables and MemTables.","response":"Bigtable writes updates to an in-memory MemTable and appends them to a commit log. When the MemTable fills, it is frozen and flushed as an immutable SSTable on disk. Compaction later merges SSTables to optimize reads."}
{"instruction":"What is the role of the timestamp oracle in Google Spanner?","response":"The timestamp oracle assigns globally unique, monotonic commit timestamps. Spanner clients contact the oracle to ensure that each transaction’s timestamp is higher than any previously issued, preserving external consistency."}
{"instruction":"Explain how a skip graph differs from a skip list.","response":"A skip graph is a distributed, peer-to-peer data structure that generalizes skip lists across nodes. Each node holds pointers at multiple levels, allowing efficient lookups in a distributed setting with O(log n) hops."}
{"instruction":"What is the PEFT approach and why is it efficient for fine-tuning LLMs?","response":"PEFT (Parameter-Efficient Fine-Tuning) updates only a small subset of parameters (e.g., via LoRA), keeping the bulk of the model frozen. This reduces memory, storage, and compute costs compared to full fine-tuning."}
{"instruction":"Describe the use of composite keys in sharded databases.","response":"Composite keys use multiple attributes (e.g., user_id + timestamp) in the hash or range function to shard data. They can improve distribution by combining high-cardinality fields but complicate query planning."}
{"instruction":"How does the high-availability guarantee differ between active–active and active–passive clusters?","response":"Active–active clusters have multiple nodes serving both reads and writes, providing higher throughput and redundancy. Active–passive clusters have standby nodes that only take over on failure, simplifying consistency but reducing utilization."}
{"instruction":"Explain how a leaderless replication protocol works.","response":"In leaderless replication (e.g., Dynamo), any node can accept writes. Writes are propagated asynchronously to N replicas, and conflict resolution (e.g., vector clocks or last-write-wins) occurs on reads or via anti-entropy processes."}
{"instruction":"What is the trade-off in choosing the number of replicas N in quorum systems?","response":"Higher N increases fault tolerance (system can lose more replicas) but increases write latency and storage overhead. Lower N reduces overhead but tolerates fewer failures and may risk data loss."}
{"instruction":"Describe how favicon-based consistent hashing (Ketama) differs from standard consistent hashing.","response":"Ketama uses a continuum of hash points per node, mapping each node to multiple positions on the ring. This smooths key distribution and reduces data movement when nodes join/leave compared to single-point hashing."}
{"instruction":"What is a store-and-forward message bus, and how does it handle failures?","response":"Store-and-forward buffers messages on intermediate nodes before forwarding. If a link fails, messages are retained until the next hop recovers, ensuring eventual delivery but with increased latency."}
{"instruction":"Explain the difference between cool and hot standby in failover systems.","response":"In hot standby, the backup node runs in ready-to-serve mode, receiving updates in real time—failover is almost instantaneous. In cold standby, the backup is idle; failover requires loading data and starting services, causing downtime."}
{"instruction":"How does the BULK LOAD operation speed up data ingestion in databases?","response":"Bulk load bypasses standard insertion paths, writing data directly into storage structures (e.g., building sorted runs or bulk-extending B-tree pages) with minimal logging or locking, greatly reducing overhead."}
{"instruction":"What is the role of the system catalog in a distributed DBMS?","response":"The system catalog stores metadata about schemas, tables, fragments, and site locations. It helps the optimizer plan distributed queries by knowing where each fragment resides and the data distribution."}
{"instruction":"Describe the difference between planner optimization and runtime adaptation in query execution.","response":"Planner optimization chooses a query plan before execution based on statistics. Runtime adaptation (adaptive query processing) adjusts the plan on the fly when actual cardinalities deviate significantly from estimates."}
{"instruction":"What is the difference between a star schema and a snowflake schema?","response":"In a star schema, a central fact table directly links to denormalized dimension tables, simplifying joins. A snowflake schema normalizes dimensions into multiple related tables, reducing redundancy but increasing join complexity."}
{"instruction":"Explain how conflict detection works in timestamp ordering protocols.","response":"Timestamp ordering assigns each transaction a timestamp. On each data access, the system compares timestamps: if a younger transaction tries to write to data read by an older one, or vice versa, the younger is aborted to preserve timestamp order."}
{"instruction":"What is the purpose of ghost records in index maintenance?","response":"Ghost records are deleted index entries retained temporarily during compaction. They allow ongoing scans to see a consistent view until the next compaction purges them, avoiding long lock holds."}
{"instruction":"Describe how adaptive radix trees (ART) improve index performance.","response":"ART dynamically changes node sizes based on the number of children, using compact representations (e.g., 4-,16-,48-,256-way nodes). This reduces memory usage and improves cache locality over fixed-size nodes in traditional tries."}
{"instruction":"Explain how a name service directory supports data location transparency.","response":"A name service directory maps logical names (e.g., table.part1) to physical locations (server addresses). Clients query the directory to locate data without needing to know its site, providing location transparency."}
{"instruction":"What is the role of the global optimizer versus local optimizers in federated DBMS?","response":"The global optimizer decomposes the query across multiple databases, deciding fragment access and join ordering across sites. Local optimizers at each site optimize subqueries against local data and indexes."}
{"instruction":"How does page-level versus tuple-level locking impact concurrency?","response":"Page-level locking locks an entire page (group of tuples), resulting in lower lock management overhead but coarser granularity and higher contention. Tuple-level locking locks individual rows, allowing finer concurrency but more locks to manage."}
{"instruction":"What is the trade-off between log shipping and remote mirroring for disaster recovery?","response":"Log shipping transfers log files periodically to a standby, allowing recovery up to the last shipped log but with potential data loss. Remote mirroring synchronously mirrors writes, providing zero data loss but higher latency."}
{"instruction":"Explain the Three-Phase Commit protocol and how it reduces blocking compared to Two-Phase Commit.","response":"Three-Phase Commit (3PC) adds a “pre-commit” phase between prepare and commit: coordinator asks participants to prepare, then sends a pre-commit to ensure they can still commit, and only then issues the final commit. If the coordinator fails, participants can safely decide to abort after pre-commit, eliminating the blocking state in 2PC."}
{"instruction":"What failure types can Three-Phase Commit tolerate that Two-Phase Commit cannot?","response":"3PC tolerates coordinator crashes during the commit phase without blocking because participants have enough state (in the pre-commit phase) to unilaterally abort or commit, whereas 2PC can block if the coordinator fails after prepare."}
{"instruction":"State the FLP impossibility result for asynchronous distributed systems.","response":"The FLP result proves that in an asynchronous system with even one crash-failure process, no deterministic consensus protocol can guarantee both safety and liveness (termination) under arbitrary network delays."}
{"instruction":"How does synchronous versus asynchronous timing affect consensus algorithms relative to FLP?","response":"In synchronous models (with known bounds on message delays and clock drift), consensus is solvable with timeouts. FLP applies to purely asynchronous models; adding timing guarantees restores solvability."}
{"instruction":"Differentiate linearizability and sequential consistency.","response":"Linearizability ensures each operation appears instantaneously at some point between invoke and response, preserving real-time order. Sequential consistency only requires operations appear in some total order consistent with each process’s program order, without respecting actual wall-clock times."}
{"instruction":"What is causal consistency and how does it compare to stronger models?","response":"Causal consistency ensures that if operation A causally precedes B, all processes see A before B; concurrent operations may be seen in any order. It’s weaker than sequential consistency but stronger than eventual consistency."}
{"instruction":"Explain the read-your-writes session guarantee.","response":"Read-your-writes ensures a client always sees its own writes in subsequent reads, preventing scenarios where a write appears to “disappear” due to eventual replication delays."}
{"instruction":"What is monotonic reads consistency?","response":"Monotonic reads guarantee that once a client has seen a particular value for a data item, it will not later see an older value, preventing “time travel” reads."}
{"instruction":"How does the PACELC theorem extend CAP?","response":"PACELC states that in the presence of a partition (P), a system trades off Availability vs. Consistency (A vs. C), and Else (under normal operation) trades off Latency vs. Consistency (L vs. C), capturing both partition and non-partition trade-offs."}
{"instruction":"Define the BASE acronym and how it contrasts with ACID.","response":"BASE stands for Basically Available, Soft state, Eventual consistency: systems prioritize availability and performance over strong consistency, in contrast to ACID’s strong correctness guarantees."}
{"instruction":"What makes a CRDT strongly eventual consistent?","response":"A CRDT provides strong eventual consistency if replicas that stop receiving updates eventually converge to the same state, without requiring coordination, thanks to commutative, associative, and idempotent merge operations."}
{"instruction":"Describe how anti-entropy mechanisms repair divergent replicas.","response":"Anti-entropy runs periodic pairwise exchanges of state (push, pull, or push-pull), comparing digests (e.g., hashes or Merkle trees) and transferring only missing updates to reconcile divergent replicas."}
{"instruction":"Compare push-based and pull-based gossip protocols.","response":"In push gossip, each node actively sends updates to random peers; in pull gossip, nodes request updates from peers. Push converges fast initially, pull is more efficient later; push-pull hybrids combine both."}
{"instruction":"What properties define an epidemic protocol?","response":"Epidemic (gossip) protocols disseminate information probabilistically via random peer exchanges, achieving high reliability, scalability, and robustness in large dynamic networks with bounded communication per node."}
{"instruction":"Explain the role of a membership service in a distributed system.","response":"A membership service tracks joining, leaving, and failing nodes, providing up-to-date lists of live nodes to other components, often via gossip or centralized registries to support failure detection and load balancing."}
{"instruction":"How does Chubby implement distributed locking?","response":"Chubby uses a Paxos-based master election to manage a replicated lock service. Clients obtain locks via a hierarchical namespace; the Chubby master coordinates lock granting and lease renewal to ensure exclusivity."}
{"instruction":"Describe the Paxos lease mechanism used in systems like Chubby.","response":"Paxos leases grant time-bound leadership: the elected leader holds a lease that expires after a known interval. If the leader fails to renew before expiry, other nodes can safely elect a new leader without risking split-brain."}
{"instruction":"What is the ZAB protocol and where is it used?","response":"Zookeeper Atomic Broadcast (ZAB) is a leader-based atomic broadcast protocol ensuring ordered delivery. It’s used by Apache Zookeeper to replicate state updates reliably to maintain a consistent service across servers."}
{"instruction":"Compare ZAB (Zookeeper) and Raft consensus protocols.","response":"Both are leader-based and ensure log replication. Raft explicitly separates leader election, log replication, and safety checks, with simpler reasoning; ZAB blends these into atomic broadcast with recovery from leader crashes via epoch numbers."}
{"instruction":"Explain viewstamped replication.","response":"Viewstamped replication uses views (epochs) with a designated primary to order client requests. On failure, a new view with a new primary is installed. It ensures safety via operation logs and view numbers."}
{"instruction":"How does atomic broadcast relate to consensus?","response":"Atomic broadcast ensures all non-faulty processes deliver the same messages in the same order. It is equivalent to consensus: each delivered message represents an agreed value in a sequence."}
{"instruction":"Define total order broadcast and its guarantees.","response":"Total order broadcast delivers messages reliably and in a single global order, preserving causal and atomic delivery guarantees, so all correct nodes see identical message sequences."}
{"instruction":"What is lazy replication and when is it used?","response":"Lazy replication propagates updates asynchronously: replicas apply writes after a delay or on demand (e.g., on reads). It reduces write latency but increases the window of inconsistency, suitable where eventual consistency suffices."}
{"instruction":"Describe active-passive replication.","response":"In active-passive (master-slave), one primary handles reads and writes, propagating updates synchronously or asynchronously to standby replicas, which remain passive until failover occurs."}
{"instruction":"Explain multi-leader replication and conflict resolution.","response":"Multi-leader allows writes on multiple nodes concurrently. Conflict resolution can be optimistic (last-write-wins) or use custom merge functions (e.g., CRDTs), but requires careful handling to avoid data loss."}
{"instruction":"How does Dynamo handle conflicting versions on reads?","response":"Dynamo returns all concurrent versions to the client, which either resolves conflicts manually or via application logic (e.g., selects the latest by timestamp or merges based on domain rules)."}
{"instruction":"What role do Merkle trees play in replica synchronization?","response":"Merkle trees compute a hash tree over key ranges, allowing replicas to compare root hashes to detect differing subtrees. Only mismatched branches are transferred, efficiently synchronizing large datasets."}
{"instruction":"How do Bloom filters optimize replica reconciliation?","response":"Bloom filters summarize sets of keys compactly, enabling a replica to quickly test whether it likely holds a key. During synchronization, they reduce unnecessary data transfers by filtering out keys already present."}
{"instruction":"What is a semi-join and how does it reduce data transfer in distributed joins?","response":"A semi-join sends only join key values of one relation to the site of the other, which returns matching keys. This filters records locally before transferring full tuples, reducing communication."}
{"instruction":"Explain the ripple join algorithm.","response":"Ripple join interleaves sampling and joining in rounds: it fetches small blocks from each relation, joins them to estimate match rates, and adaptively decides which relation to sample next, minimizing I/O."}
{"instruction":"How does a shuffle-based join work in MapReduce frameworks?","response":"Shuffle join partitions both relations by join key across workers, then each worker sorts or hashes its partitions and performs the local join. The shuffle phase routes matching keys to the same reducer."}
{"instruction":"Describe the cost model components for distributed join ordering.","response":"Cost models account for CPU (processing tuples), I/O (reading/writing partitions), and network transfer (shuffling data across sites), with weights for latency and bandwidth to choose optimal join sequences."}
{"instruction":"What is a distributed histogram, and why is it used?","response":"A distributed histogram collects approximate value distributions of attributes across partitions. The optimizer uses it to estimate selectivities and cardinalities for join ordering in distributed queries."}
{"instruction":"Explain adaptive query processing.","response":"Adaptive query processing monitors actual cardinalities and selectivities during execution, dynamically adjusting plans (e.g., switching join algorithms or reordering joins) when estimates deviate significantly from reality."}
{"instruction":"What is locality-aware scheduling in distributed query engines?","response":"Locality-aware schedulers assign tasks to nodes where data resides (or nearby), minimizing network transfer, improving throughput, and reducing latency for distributed query execution."}
{"instruction":"How does data skew impact distributed joins, and how can it be mitigated?","response":"Skew causes some partitions to have disproportionate data, leading to stragglers. Mitigation includes redistribution strategies (e.g., range partitioning), fine-grained partitioning, or dynamic work stealing."}
{"instruction":"Describe partition pruning and dynamic partition elimination.","response":"Partition pruning uses metadata to skip scanning partitions that cannot satisfy query predicates. Dynamic partition elimination evaluates predicates at runtime to further exclude partitions based on runtime parameters."}
{"instruction":"What role does the system catalog play in federated queries?","response":"In federated DBMS, the system catalog stores metadata about remote data sources, schemas, partitions, and statistics, enabling the global optimizer to generate cross-site query plans."}
{"instruction":"How does the optimizer estimate cardinalities in a distributed context?","response":"It collects statistics (histograms, samples) per fragment and combines them across sites, applying selectivity formulas and adjusting for network costs and remote I/O when estimating join sizes."}
{"instruction":"Explain network-aware fragmentation strategies.","response":"Network-aware fragmentation places data fragments on nodes to minimize high-latency links for predicted query patterns, balancing load and reducing cross-site communication costs."}
{"instruction":"How is site autonomy preserved in federated DBMS architectures?","response":"Each site manages its own storage engine, security, and query execution. The federated layer translates global queries into local subqueries without imposing global transaction control, preserving autonomy."}
{"instruction":"Define a global deadlock and how it can be detected.","response":"A global deadlock spans multiple sites when transactions waiting for locks form a cycle across sites. Detection involves constructing a distributed wait-for graph via site coordinators and detecting cycles."}
{"instruction":"Describe distributed deadlock detection using probe messages.","response":"Site A sends probes to site B when waiting for resources; probes propagate along wait-for edges. If a probe returns to the origin, a cycle (deadlock) is detected, and a victim transaction is chosen to abort."}
{"instruction":"What are the roles of a query coordinator and query workers in parallel DBMS?","response":"The coordinator parses and optimizes the query, then dispatches subqueries to workers (nodes). Workers execute operators on local data and return results or intermediate data to the coordinator for final assembly."}
{"instruction":"Explain how YARN schedules tasks for a distributed DBMS on Hadoop.","response":"YARN’s ResourceManager allocates containers across nodes; the ApplicationMaster requests resources for query tasks, which run inside containers on DataNodes, leveraging data locality and dynamic resource sharing."}
{"instruction":"What is the role of the metadata server and chunkserver in Google File System (GFS)?","response":"The metadata server (master) maintains namespace, file-to-chunk mappings, and access control, while chunkservers store fixed-size data chunks and handle read/write requests, reporting heartbeats and chunk statuses back to the master."}
{"instruction":"How do HDFS NameNode and DataNode coordinate file operations?","response":"The NameNode manages the filesystem metadata and namespace, directing clients to DataNodes. DataNodes store blocks and send heartbeats and block reports, allowing the NameNode to track block locations and replicate for fault tolerance."}
{"instruction":"Compare erasure coding to replication for fault tolerance in distributed storage.","response":"Replication achieves fault tolerance by storing full copies on multiple nodes, offering fast recovery but high storage overhead. Erasure coding splits data into k data and m parity fragments, tolerating m failures with lower storage overhead but higher compute and repair costs."}
{"instruction":"How do lease-based mechanisms improve caching in GFS?","response":"Leases grant a primary chunkserver exclusive write permissions for a time window, allowing clients to pipeline writes and caching locally without coordination per write, reducing metadata server load and improving write throughput."}
{"instruction":"Explain stripe width and stripe size in distributed file striping.","response":"Stripe size is the amount of contiguous data written to one storage unit before moving on; stripe width is the number of units data is striped across. Together they determine parallelism, I/O granularity, and optimal I/O sizes for performance."}
{"instruction":"Describe how ZooKeeper ensembles achieve reliability.","response":"A ZooKeeper ensemble uses an odd number of servers. It relies on majority quorum for leader election and writes: as long as a majority are up, the service continues. Followers replicate the leader’s write-ahead log to ensure state consistency."}
{"instruction":"What is MVCC and how is it applied in distributed databases like TiDB?","response":"MVCC stores multiple versions of each row tagged with commit timestamps. TiDB uses per-region MVCC to serve consistent snapshots for transactions, enabling readers to access past versions without blocking writers and ensuring snapshot isolation."}
{"instruction":"How does HBase perform region splitting and load balancing?","response":"When a region grows beyond a threshold, HBase splits it into two at a row key boundary. The Master tracks region sizes and moves overloaded regions to less busy RegionServers, using assignment algorithms to balance load across the cluster."}
{"instruction":"Contrast columnar and row-oriented stores for analytical workloads.","response":"Columnar stores organize data by column, enabling high compression and vectorized execution for OLAP queries that scan few columns over many rows. Row stores excel at OLTP workloads with point lookups and frequent small updates."}
{"instruction":"Define OLAP versus OLTP in the context of distributed databases.","response":"OLTP systems handle high-throughput, low-latency transactional workloads (inserts/updates/deletes) with strict consistency. OLAP systems perform complex analytical queries over large datasets, prioritizing throughput and scan efficiency over latency."}
{"instruction":"How do NewSQL systems like VoltDB manage distributed transactions?","response":"VoltDB uses partitioned data and a single-threaded execution engine per partition, eliminating locking. Transactions run as stored procedures that execute serially per partition, achieving ACID guarantees and high throughput without two-phase commit."}
{"instruction":"Why might a system use consensus (e.g., Raft) instead of Two-Phase Commit for distributed commits?","response":"Consensus protocols like Raft provide leader election, log replication, and safety under node failures, enabling state machine replication with liveness guarantees in asynchronous networks. 2PC blocks on coordinator failure and lacks a built-in recovery consensus."}
{"instruction":"Differentiate federated and distributed databases.","response":"Federated databases integrate autonomous heterogeneous databases via a middleware layer, preserving local autonomy and schemas. Distributed databases partition or replicate a single database across multiple nodes under a unified schema and transaction manager."}
{"instruction":"How do data localization laws affect fragmentation strategies?","response":"Data localization regulations require certain data to remain within geographical boundaries. Fragmentation predicates incorporate site-specific rules so that fragments containing regulated data reside only on compliant locations, ensuring legal adherence."}
{"instruction":"Explain schema-on-read versus schema-on-write in big data systems.","response":"Schema-on-write enforces a schema at data ingestion, as in traditional RDBMS, ensuring data cleanliness upfront. Schema-on-read defers schema enforcement to query time, as in Hadoop, providing flexibility for varied data but potentially slower reads."}
{"instruction":"Describe the Lambda architecture and its trade-offs.","response":"Lambda architecture consists of a batch layer for comprehensive but high-latency processing, a speed layer for low-latency updates, and a serving layer that merges results. It offers fault tolerance and up-to-date views but increases system complexity and maintenance overhead."}
{"instruction":"What is the Kappa architecture and how does it differ from Lambda?","response":"Kappa uses a single streaming pipeline for both real-time and reprocessing, eliminating the batch layer of Lambda. All data is treated as a stream, simplifying architecture and reducing code duplication but relying on a robust streaming platform."}
{"instruction":"How do stream processing and batch processing complement each other in modern databases?","response":"Batch processing handles large-scale, high-throughput analytics with high latency, while stream processing ingests and analyzes data in real time with low latency. Together, they provide both historical insights and immediate responses to events."}
{"instruction":"Explain fault tolerance in Apache Kafka using replication factors.","response":"Kafka replicates each partition across multiple brokers (replication factor RF). The leader handles reads/writes while followers replicate data. A write is acknowledged when written to the leader and optionally to ISR (in-sync replicas), tolerating up to RF−1 broker failures."}
{"instruction":"What mechanisms enable exactly-once semantics in stream processing frameworks?","response":"Exactly-once requires atomic writes, idempotent state updates, and checkpointing. Systems use transactional writes to sinks and two-phase commit protocols on state backends, combined with coordinated snapshots to ensure no data is processed or output twice."}
{"instruction":"How does Flink perform checkpointing for stateful stream processing?","response":"Flink periodically triggers distributed snapshots: operators emit checkpoint barriers that flow through the dataflow graph. Each operator captures its state at the barrier, and once barriers reach sinks, the checkpoint is committed, enabling consistent recovery."}
{"instruction":"What is backpressure in stream processing systems, and how is it handled?","response":"Backpressure occurs when downstream operators process slower than upstream emit rate. Systems propagate backpressure signals upstream to throttle sources or buffer data, preventing resource exhaustion and ensuring stability under load."}
{"instruction":"Compare rendezvous hashing (HRW) and consistent hashing.","response":"Rendezvous hashing assigns each key to the node with the highest hash score for that key-node pair, requiring O(N) computation per lookup but minimal movement on node changes. Consistent hashing uses a ring and virtual nodes, offering O(log N) lookup and bounded movement."}
{"instruction":"Describe the SWIM gossip-based failure detector.","response":"SWIM (Scalable Weakly-consistent Infection-style Membership) periodically pings random peers. If a ping fails, it requests an indirect ping via other nodes. Suspected nodes are flagged and eventually declared failed if suspicion persists, balancing speed and overhead."}
{"instruction":"What is the power-of-two-choices load balancing algorithm?","response":"Each request probes two random servers and selects the one with the smaller load. This simple scheme dramatically reduces maximum load compared to purely random assignment, improving balancing with minimal coordination."}
{"instruction":"Contrast vector clocks and Lamport clocks.","response":"Lamport clocks assign a scalar timestamp per event, capturing partial order but not concurrency. Vector clocks use an array of counters per node, capturing causality and concurrency precisely but requiring O(N) metadata per event."}
{"instruction":"How do hybrid logical clocks (HLC) combine physical and logical clocks?","response":"HLC include a physical timestamp and a logical counter. On send, timestamp is max(local_phys, recv_phys), incrementing counter if equal. On receive, it takes max of sender and local HLC. This preserves causality with bounded clock skew."}
{"instruction":"Explain transparent data encryption in distributed databases.","response":"Transparent Data Encryption (TDE) encrypts data at rest at the storage layer using per-table or per-database keys. Encryption and decryption occur within the database engine, invisible to applications, ensuring data confidentiality on disk."}
{"instruction":"How do multi-tenant cloud databases ensure isolation?","response":"They provision separate logical schemas or databases per tenant, enforce row-level security, and use resource governance (CPU, memory, I/O quotas) and namespace isolation to prevent data leakage and noisy-neighbor effects."}
{"instruction":"What scaling mechanism do serverless databases use?","response":"Serverless databases automatically add or remove compute resources (containers/functions) based on workload metrics, leveraging stateless query engines and autoscaling storage layers to elastically match demand without manual sharding."}
{"instruction":"Describe cold and hot data tiering in distributed storage.","response":"Hot tier stores frequently accessed data on low-latency, high-cost media (e.g., SSDs). Cold tier archives infrequently used data on high-capacity, lower-cost media (e.g., HDDs or cloud object storage), balancing cost and performance."}
{"instruction":"What constraints do edge databases face in IoT scenarios?","response":"Edge databases must operate with limited compute, memory, and intermittent connectivity. They prioritize local processing, lightweight storage engines, eventual consistency, and efficient sync protocols to central or peer nodes."}
{"instruction":"Compare blockchain consensus (e.g., Proof-of-Work) with traditional consensus protocols.","response":"Proof-of-Work relies on computational puzzles and probabilistic finality, enabling open membership at the cost of high latency and energy. Traditional protocols like Raft assume fixed membership, deterministic safety, and faster, lower-cost consensus."}
{"instruction":"Explain the trade-off between transaction throughput and latency.","response":"Higher throughput often bins or batches transactions, amortizing overhead but increasing per-transaction latency. Low-latency systems favor immediate commit paths with less batching, trading off throughput due to higher coordination costs per transaction."}
{"instruction":"What advantages do in-memory databases offer, and how do they ensure durability?","response":"In-memory databases provide low-latency reads/writes by keeping data in RAM. To ensure durability, they use write-ahead logs on disk, periodic snapshots, or non-volatile memory, persisting state to survive node failures."}
{"instruction":"Describe the architecture of a distributed in-memory database like SingleStore (formerly MemSQL).","response":"SingleStore uses a distributed cluster with leaf nodes storing data in-memory and disk, and aggregator nodes parsing SQL and routing queries. Data is sharded across leaves, using both row and column formats for OLTP and OLAP in a single engine."}
{"instruction":"How do cloud databases rebalance shards elastically?","response":"Elastic rebalancing monitors shard load and storage utilization. When thresholds are exceeded, the system migrates partitions to underutilized nodes, updating metadata atomically and throttling data movement to minimize impact on queries."}
{"instruction":"What is polyglot persistence and when is it beneficial?","response":"Polyglot persistence uses multiple database technologies within one application, choosing the best fit per data model or access pattern (e.g., relational for transactions, document store for flexible schemas, graph DB for network queries), optimizing performance and developer productivity."}
{"instruction":"Explain the use of materialized views in distributed databases.","response":"Materialized views precompute and store the results of complex queries. In distributed databases, they reduce network traffic and latency by co-locating aggregated or joined data fragments, trading storage and maintenance cost for faster reads."}
{"instruction":"What challenges arise with incremental view maintenance in distributed systems?","response":"Incremental maintenance must propagate base table updates to materialized views across partitions atomically. Challenges include coordination overhead, handling out-of-order updates, and ensuring consistency under concurrent writes and failures."}
{"instruction":"How do distributed proxies route queries to shards?","response":"Distributed proxies maintain routing metadata mapping keys or query predicates to shard locations. They parse incoming queries, determine target shards (e.g., via hash/range), and forward subqueries, aggregating results before returning to the client."}
{"instruction":"Contrast cost-based and heuristic-based query optimization.","response":"Cost-based optimizers estimate plan costs using statistics and choose the lowest-cost plan, providing high-quality plans but requiring up-to-date stats. Heuristic-based optimizers apply rule-based transformations quickly but may miss optimal plans without cost evaluation."}
{"instruction":"What is adaptive indexing (database cracking)?","response":"Adaptive indexing incrementally builds indexes as queries run by reorganizing data on-the-fly based on predicates. Over time, the database “learns” common access patterns without explicit index creation, balancing initial query overhead with long-term performance gains."}
{"instruction":"Describe data compaction strategies in distributed key-value stores.","response":"Compaction merges sorted files or log segments to remove deleted/expired entries and consolidate data. Strategies include minor compactions for small merges, major compactions for deep cleanup, and tiered compactions balancing write amplification and read performance."}
{"instruction":"What is a failure detector in distributed systems, and what are its main classes?","response":"A failure detector provides hints about which processes have crashed. Main classes include Perfect (no false suspicions, eventual completeness), Eventually Perfect (may err initially but eventually accurate), Strong (no false suspicions), and Eventually Strong (eventually no mistakes about at least one correct process)."}
{"instruction":"Describe the Omega failure detector and its significance.","response":"Omega eventually provides a single correct leader process to all nodes. It’s the weakest detector sufficient to solve consensus in asynchronous systems with crash failures, enabling many practical consensus protocols to operate under partial synchrony."}
{"instruction":"What is the partial synchrony model in distributed computing?","response":"Partial synchrony assumes unknown but finite bounds on message delays or processing speeds. Systems may behave asynchronously initially but stabilize to synchronous behavior, allowing consensus protocols to terminate despite unpredictable delays."}
{"instruction":"Explain the PBFT (Practical Byzantine Fault Tolerance) protocol.","response":"PBFT is a leader-based protocol tolerating f Byzantine faults among 3f+1 replicas. In the common case, the leader orders requests, replicates them to backups, and commits once a quorum of 2f+1 PREPARE and COMMIT messages are exchanged, ensuring safety and liveness."}
{"instruction":"How do Byzantine faults differ from crash faults?","response":"Crash faults simply stop a node’s execution, while Byzantine faults allow arbitrary, potentially malicious behavior (sending conflicting or incorrect messages), requiring stronger replication and agreement protocols to tolerate."}
{"instruction":"What quorum size is needed in Byzantine quorum systems and why?","response":"Byzantine quorum systems require quorums of size ≥2f+1 out of 3f+1 replicas to ensure any two quorums intersect in at least f+1 correct nodes, preventing faulty nodes from driving conflicting decisions."}
{"instruction":"What is the common-case optimization in PBFT?","response":"PBFT’s common-case path skips the full view-change protocol when the leader is correct: requests flow from client to leader (PRE-PREPARE), then to backups (PREPARE) and commit (COMMIT) with minimal additional checks, reducing latency."}
{"instruction":"Describe the view-change process in PBFT.","response":"If the leader is suspected faulty, replicas broadcast VIEW-CHANGE messages including their latest stable checkpoint and logs. A new leader collects 2f+1 VIEW-CHANGE messages, determines the committed request sequence, sends a NEW-VIEW, and normal operation resumes under the new view."}
{"instruction":"What is reliable broadcast in distributed systems?","response":"Reliable broadcast guarantees that if a correct sender broadcasts a message, all correct receivers eventually deliver it, and no message is delivered twice or spurious. Often implemented using quorum and echo phases to ensure agreement despite failures."}
{"instruction":"How do gossip-based membership protocols work?","response":"Each node periodically selects random peers to exchange membership lists or heartbeats. Over repeated rounds, updates propagate probabilistically across the cluster, achieving high scalability and eventual consistency in membership views."}
{"instruction":"Contrast a database monolith with a microservices architecture.","response":"A monolith bundles all functionality (business logic, data models) into one deployable unit, simplifying cross-component transactions but risking large deployments. Microservices split functionality into independent services, each with its own data store, improving modularity and scalability at the cost of distributed transactions."}
{"instruction":"What role does an API gateway play in a microservices-based data platform?","response":"An API gateway routes client requests to appropriate microservices, handles authentication, rate limiting, request aggregation, and can implement caching, reducing client complexity and centralizing cross-cutting concerns."}
{"instruction":"Describe common distributed caching patterns.","response":"Patterns include: write-through (cache updated on writes synchronously), write-back (writes buffered in cache and lazily persisted), read-through (cache fetches on misses), and cache-aside (application manages cache loading and invalidation)."}
{"instruction":"What is the difference between write-through and write-back caching?","response":"Write-through updates both cache and backing store on each write, ensuring data durability but incurring higher latency. Write-back writes only to cache and later persists to store, improving write performance but risking data loss on cache failures."}
{"instruction":"How does TTL-based eviction work in caches?","response":"Each cached entry is stamped with a time-to-live (TTL) upon insertion. When an entry’s TTL expires, it is considered stale and evicted on the next access or by a background thread, ensuring freshness at the cost of potential cache churn."}
{"instruction":"Explain LRU eviction and its trade-offs.","response":"Least-Recently-Used (LRU) evicts the entry that hasn’t been accessed for the longest time. It’s simple and approximates good hit rates, but requires tracking access order (via linked lists or counters), which adds metadata overhead."}
{"instruction":"What is lease-based cache coherence?","response":"A lease grants a cache exclusive read or write rights for a bounded time. After lease expiry, caches must revalidate or fetch updates, reducing synchronization overhead but requiring careful lease duration tuning to balance freshness and performance."}
{"instruction":"How does consistent hashing aid cache sharding?","response":"Consistent hashing divides a hash ring among cache nodes. Keys map to points on the ring, assigned to the next node clockwise. When nodes join/leave, only O(1/N) keys move, enabling low-overhead resharding and even load distribution."}
{"instruction":"What are benefits of client-side caching in distributed systems?","response":"Client-side caches reduce load on central services, lower latency for repeated accesses, and improve perceived performance. They require cache invalidation or coherence protocols to prevent stale reads."}
{"instruction":"How can RDMA improve distributed database performance?","response":"RDMA enables direct memory-to-memory transfers between nodes bypassing the kernel, reducing latency and CPU overhead for communication. It’s used in high-performance clusters for fast key-value stores and distributed transactions."}
{"instruction":"Describe how NVMe over Fabrics (NVMe-oF) enhances storage access.","response":"NVMe-oF extends NVMe protocol over networks (RDMA, TCP), allowing remote access to NVMe devices. It preserves NVMe’s low-latency, high-throughput semantics, enabling disaggregated storage architectures with minimal performance loss."}
{"instruction":"What role do FPGAs play in accelerating database operations?","response":"FPGAs can offload compute-intensive tasks (e.g., filtering, aggregation, encryption) directly in hardware pipelines, reducing latency and CPU usage. They are integrated as smart NICs or PCIe cards in modern database accelerators."}
{"instruction":"How is GPU acceleration used in analytical query processing?","response":"GPUs execute parallelizable operations (scans, joins, aggregations) using thousands of cores and SIMD pipelines. Data is transferred to GPU memory, processed massively in parallel, and results returned, yielding high throughput for OLAP workloads."}
{"instruction":"Explain trade-offs of erasure coding in distributed storage.","response":"Erasure coding reduces storage overhead compared to replication by splitting data into k data and m parity blocks. It tolerates m failures but incurs higher CPU for encoding/decoding and network cost during repair, trading storage for compute and bandwidth."}
{"instruction":"What are fountain codes and when are they used?","response":"Fountain codes (e.g., LT, Raptor) generate potentially unlimited parity symbols from k data symbols. A decoder can recover the original k symbols from any k+ε symbols. They’re used in streaming and large-scale distributed storage to handle variable loss rates."}
{"instruction":"Describe WORM storage and its applications.","response":"Write-Once-Read-Many (WORM) storage permits data to be written only once and then only read. It’s used for compliance archives, tamper-evident logs, and secure backups where immutability is critical."}
{"instruction":"What features distinguish time-series databases from general-purpose databases?","response":"Time-series DBs optimize for sequential time-based writes, high insert rates, and range queries over time windows. They use compression schemes (delta encoding), downsampling, retention policies, and specialized indexing for efficient temporal analytics."}
{"instruction":"Contrast LSM-tree and B-tree storage engines.","response":"LSM-trees buffer writes in memory and periodically flush sorted runs to disk, optimizing write throughput but requiring compaction to merge runs. B-trees update pages in place, offering low-latency reads and simpler reads at the cost of random write amplification."}
{"instruction":"What is a compaction filter in LSM-based stores?","response":"A compaction filter applies custom logic to keys/values during compaction, such as TTL expiration, custom deletions, or transformation of data, enabling on-the-fly cleanup or migration without client intervention."}
{"instruction":"Explain tiered storage in modern distributed databases.","response":"Tiered storage moves colder data to cheaper, higher-latency media (HDD, object store) and keeps hot data on SSD or in-memory tiers. Policies based on access patterns or age automate data flow, optimizing cost-performance trade-offs."}
{"instruction":"How is multi-tenancy isolation achieved in shared clusters?","response":"Isolation uses namespace segmentation (separate schemas/databases per tenant), resource governance (CPU/memory quotas, I/O throttling), and security policies (row- or tenant-level access controls) to prevent noisy neighbors and data leaks."}
{"instruction":"What are resource quotas and how do they enforce fair usage?","response":"Resource quotas limit tenant consumption of CPU, memory, disk I/O, and network resources. The system monitors usage and throttles or rejects requests exceeding quotas, ensuring fair sharing and preventing overcommitment."}
{"instruction":"Describe role-based access control (RBAC) in distributed databases.","response":"RBAC assigns permissions to roles (e.g., reader, writer, admin) and grants roles to users or groups. The database enforces access by checking role permissions on each operation, simplifying security management in large teams."}
{"instruction":"What’s the difference between encryption at-rest and encryption in-transit?","response":"At-rest encryption secures data on storage media using disk- or file-level keys, protecting against physical compromise. In-transit encryption (TLS/SSL) secures data over the network, preventing eavesdropping or tampering during transmission."}
{"instruction":"Explain field-level encryption and its use cases.","response":"Field-level encryption encrypts specific sensitive columns (e.g., SSNs, credit cards) within a record using application-managed keys. It protects data even if the database or storage is compromised but requires client-side or secure enclave operations for queries."}
{"instruction":"What is homomorphic encryption and why is it promising for databases?","response":"Homomorphic encryption allows computations on ciphertexts without decryption, producing encrypted results that decrypt to the correct plaintext outputs. It enables secure query processing on untrusted servers but is currently limited by high computational overhead."}
{"instruction":"How does differential privacy protect aggregate query results?","response":"Differential privacy adds calibrated noise to query results based on a privacy budget, ensuring that the presence or absence of any single record has a bounded influence on outputs, protecting individual data privacy in analytics."}
{"instruction":"What impact do data localization laws have on distributed database design?","response":"Laws like GDPR may require data residency in specific regions. Designers must partition or replicate data according to jurisdictional policies, restrict cross-border data flows, and enforce geofencing in fragmentation predicates and replication policies."}
{"instruction":"Describe the consistency model of S3 object storage.","response":"S3 provides read-after-write consistency for PUTs of new objects in US West-2 and read-after-write eventual consistency for overwrite PUTs and DELETEs, ensuring new objects are immediately visible but requiring time for updates to propagate."}
{"instruction":"What consistency options does DynamoDB offer?","response":"DynamoDB supports eventual consistency by default, offering strong consistency as an option per-read. Strong reads always reflect the latest successful write, while eventual reads may return stale data but have lower latency and cost."}
{"instruction":"Explain provisioned versus on-demand capacity modes in DynamoDB.","response":"Provisioned mode requires specifying read/write throughput units in advance, offering predictable performance and cost. On-demand mode automatically scales capacity to workload, simplifying operations at the expense of potentially higher per-request costs."}
{"instruction":"What are global secondary indexes (GSIs) in DynamoDB?","response":"GSIs index non-primary key attributes to support alternate query patterns. They maintain their own provisioned capacity and eventual consistency, allowing queries on different attributes without scanning the entire table."}
{"instruction":"How does TTL (time-to-live) work in DynamoDB tables?","response":"TTL marks items with an expiration timestamp. A background process scans and automatically deletes expired items, reducing storage and maintenance overhead without explicit delete operations in application code."}
{"instruction":"What is the hot key problem and how can it be mitigated?","response":"A hot key receives disproportionate traffic, causing contention and uneven load. Mitigation strategies include key salting (appending random shards), dynamic sharding, or request routing to replicate hot keys across partitions."}
{"instruction":"Describe scatter-gather in distributed query execution.","response":"Scatter-gather sends subqueries to all relevant nodes (scatter), each processes data locally, and returns partial results, which a coordinator gathers and merges (gather) to form the final query answer, enabling parallelism."}
{"instruction":"How do Delta Lake and other data lakes provide ACID transactions?","response":"Delta Lake uses a transaction log (Delta Log) to record metadata changes and file additions/deletions atomically. Readers consult the log for consistent snapshots, and writers use optimistic concurrency control to commit changes reliably."}
{"instruction":"What is Apache Iceberg and how does it differ from Delta Lake?","response":"Iceberg is an open table format for huge analytic datasets. It tracks table metadata in manifest files and supports hidden partitioning, schema evolution, time travel, and optimized file-level operations, offering similar ACID semantics but with pluggable engine support."}
{"instruction":"Compare Apache Hive and Presto for SQL-on-Hadoop workloads.","response":"Hive compiles queries to MapReduce or Tez jobs, optimizing large batch scans with high latency. Presto is a distributed MPP engine that executes queries in-memory with pipelined execution, offering much lower latency for ad-hoc analytics."}
{"instruction":"Explain Snowflake’s multi-cluster shared data architecture.","response":"Snowflake separates storage and compute: data is stored in a central repository accessible by multiple independent compute clusters (virtual warehouses). Each cluster scales elastically, isolating workloads while sharing the same consistent data layer."}
{"instruction":"What factors influence the cost of cross-region distributed transactions?","response":"Cross-region transactions incur higher network latency, egress charges, and longer commit times due to protocol round-trips. Costs rise with stricter consistency (sync replication), higher contention, and data transfer volumes between regions."}
{"instruction":"What are the “Presumed Abort” and “Presumed Commit” optimizations in Two-Phase Commit, and how do they reduce logging overhead?","response":"In Presumed Abort, a participant only logs a commit if it actually commits; on recovery, absence of a commit record implies an abort, saving log writes for aborts. In Presumed Commit, a participant logs an abort only if it aborts; recovery assumes commit by default, saving log writes for commits. Both reduce the number of forced log records and I/O by relying on protocol assumptions during recovery."}
{"instruction":"What are phantom reads in database isolation, and how can predicate locking prevent them?","response":"A phantom read occurs when a transaction re-executes a query returning a set of rows matching a predicate and finds new rows that were inserted by another transaction. Predicate locking prevents phantoms by acquiring locks on the entire predicate range (not just existing rows), blocking inserts that would satisfy the predicate until the locking transaction commits."}
